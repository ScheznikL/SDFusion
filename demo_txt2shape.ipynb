{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a46PIolBovog"
      },
      "source": [
        "# SDFusion: Text-guided Generation (txt2shape)\n",
        "\n",
        "### TODO: add sample results or teaser images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ScheznikL/SDFusion.git\n",
        "%cd SDFusion\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YML3ilOsqZZO",
        "outputId": "99c28d7b-1d00-4a85-eb5d-4a4c220c5c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SDFusion'...\n",
            "remote: Enumerating objects: 2003, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 2003 (delta 48), reused 36 (delta 36), pack-reused 1942 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2003/2003), 36.02 MiB | 8.58 MiB/s, done.\n",
            "Resolving deltas: 100% (832/832), done.\n",
            "Updating files: 100% (2464/2464), done.\n",
            "/content/SDFusion\n",
            "configs\t\t      demo_mm2shape.ipynb\t    LICENSE\tsetup_env.sh\n",
            "dataset_info_files    demo_txt2shape.ipynb\t    models\ttrain.py\n",
            "datasets\t      demo_uncond_shape_comp.ipynb  options\tutils\n",
            "demo_data\t      external\t\t\t    preprocess\n",
            "demo_img2shape.ipynb  launchers\t\t\t    README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngTOHKKoovoj"
      },
      "outputs": [],
      "source": [
        "# first set up which gpu to use\n",
        "import os\n",
        "gpu_ids = 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_ids}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exit()\n",
        "#How to run a Python script in a '.py' file from a Google Colab notebook?\n",
        "from models.base_model import create_model"
      ],
      "metadata": {
        "id": "RH49NE8R1det"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py joblib trimesh scipy PyMCubes\n",
        "#pip install --upgrade PyMCubes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whf2UAAO4Ic7",
        "outputId": "46725605-282c-4cef-ddb4-4c950518dfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.6.8-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Collecting PyMCubes\n",
            "  Downloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Downloading trimesh-4.6.8-py3-none-any.whl (709 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.8/336.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh, PyMCubes\n",
            "Successfully installed PyMCubes-0.1.6 trimesh-4.6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"2.1.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiMDwTPe5ajn",
        "outputId": "9e8c058a-305e-4c09-ad25-388f456a9ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git@stable\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git (to revision stable) to /tmp/pip-req-build-l19d08cn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-l19d08cn\n",
            "  Running command git checkout -q 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 75ebeeaea0908c5527e7b1e305fbc7681382db47\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath (from pytorch3d==0.7.8)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.13.2)\n",
            "Collecting portalocker (from iopath->pytorch3d==0.7.8)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: pytorch3d, iopath\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4rc3dvRovok"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "from IPython.display import Image as ipy_image\n",
        "from IPython.display import display\n",
        "from termcolor import colored, cprint\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from models.base_model import create_model\n",
        "from utils.util_3d import render_sdf, render_mesh, sdf_to_mesh, save_mesh_as_gif\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "hiAWSzGrym7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "id": "nnCrwizmJOFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5F5K37covom"
      },
      "outputs": [],
      "source": [
        "# @title Seed 2024\n",
        "# options for the model. please check `utils/demo_util.py` for more details\n",
        "from utils.demo_util import SDFusionText2ShapeOpt\n",
        "\n",
        "seed = 2024\n",
        "opt = SDFusionText2ShapeOpt(gpu_ids=gpu_ids, seed=seed)\n",
        "device = opt.device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir saved_ckpt"
      ],
      "metadata": {
        "id": "FO-FyCz4J6mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SDFusion: text-guided shape generation (txt2shape)\n",
        "!wget https://uofi.box.com/shared/static/vyqs6aex3rwbgxweyl3qh21c8p6vu33f.pth -O saved_ckpt/sdfusion-txt2shape.pth\n",
        "# VQVAE's checkpoint\n",
        "!wget https://uofi.box.com/shared/static/zdb9pm9wmxaupzclc7m8gzluj20ja0b6.pth -O saved_ckpt/vqvae-snet-all.pth"
      ],
      "metadata": {
        "id": "RB_TIaXOJw7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE1vp0Owovon"
      },
      "outputs": [],
      "source": [
        "#@title initialize SDFusion model\n",
        "ckpt_path = 'saved_ckpt/sdfusion-txt2shape.pth'\n",
        "opt.init_model_args(ckpt_path=ckpt_path)\n",
        "\n",
        "SDFusion = create_model(opt)\n",
        "cprint(f'[*] \"{SDFusion.name()}\" loaded.', 'cyan')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeqFgJDoovon"
      },
      "source": [
        "## SDFusion: text-guided generation (txt2shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "tGnRcZk0ovon",
        "outputId": "a30580ab-2627-40ab-f5d7-e99feadfd574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-29 01:28:25.815905: Starting txt2shape generation\n",
            "Data shape for DDIM sampling is (1, 3, 16, 16, 16), eta 0.0\n",
            "Running DDIM Sampling with 100 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DDIM Sampler: 100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-29 01:29:07.523167: Completed sdf_to_mesh\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Save meshes to .obj and/or .ply\\nfor i, mesh in enumerate(mesh_gen):\\n    verts, faces = mesh.verts_packed(), mesh.faces_packed()\\n    # Save to .obj format\\n    obj_path = f\"{out_dir}/shape_{i}_{input_txt.replace(\\' \\', \\'_\\')}.obj\"\\n    save_obj(obj_path, verts, faces)\\n    print(f\"Saved OBJ to {obj_path}\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# txt2shape\n",
        "out_dir = 'demo_results'\n",
        "if not os.path.exists(out_dir): os.makedirs(out_dir)\n",
        "\n",
        "# change the input text here to generate different chairs/tables!\n",
        "input_txt_old = \"A round red color chair with four legs 0.5 meters in length each\"\n",
        "input_txt = \"Generate a chair with four legs of 0.53 meters in length, a round seat cushion with a radius of 1/2 of leg length, and a slat back with gaps of 0.11 meters.\"\n",
        "book_case_txt = \"Generate a bookcase with 4 drawers on top of short bolt legs 0.3 meters each and 3 wide open shelves\"\n",
        "ngen = 1 # number of generated shapes\n",
        "ddim_steps = 100\n",
        "ddim_eta = 0.\n",
        "uc_scale = 3.\n",
        "# Log start time\n",
        "start_time = datetime.now()\n",
        "print(f\"{start_time}: Starting txt2shape generation\")\n",
        "\n",
        "sdf_gen = SDFusion.txt2shape(input_txt=book_case_txt, ngen=ngen, ddim_steps=ddim_steps, ddim_eta=ddim_eta, uc_scale=uc_scale)\n",
        "\n",
        "# Log after sdf_to_mesh generation\n",
        "end_time = datetime.now()\n",
        "print(f\"{end_time}: Completed sdf_to_mesh\")\n",
        "\n",
        "mesh_gen = sdf_to_mesh(sdf_gen)\n",
        "\n",
        "'''# Save meshes to .obj and/or .ply\n",
        "for i, mesh in enumerate(mesh_gen):\n",
        "    verts, faces = mesh.verts_packed(), mesh.faces_packed()\n",
        "    # Save to .obj format\n",
        "    obj_path = f\"{out_dir}/shape_{i}_{input_txt.replace(' ', '_')}.obj\"\n",
        "    save_obj(obj_path, verts, faces)\n",
        "    print(f\"Saved OBJ to {obj_path}\")'''\n",
        "\n",
        "# vis as gif\n",
        "#gen_name = f'{out_dir}/txt2shape-{input_txt}.gif'\n",
        "#save_mesh_as_gif(SDFusion.renderer, mesh_gen, nrow=3, out_name=gen_name)\n",
        "\n",
        "#print(f'Input: \"{input_txt}\"')\n",
        "#for name in [gen_name]:\n",
        "#    display(ipy_image(name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title save Mesh\n",
        "#from pytorch3d.io import save_mesh\n",
        "from pathlib import Path\n",
        "from pytorch3d.io import IO\n",
        "\n",
        "out_dir = 'demo_results'\n",
        "\n",
        "for i, mesh in enumerate(mesh_gen):\n",
        "  #mesh.textures.faces_verts_textures_packed()\n",
        "\n",
        "    mesh_path = Path(out_dir) / f\"seed2024shape_{i}_{input_txt.split(maxsplit=1)[0]}.ply\"\n",
        "    IO().save_mesh(mesh, mesh_path,include_textures=True) #binary=False, colors_as_uint8=True\n",
        "\n",
        "# Directory for saving meshes\n",
        "#out_dir = 'demo_results'\n",
        "#Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Iterate through generated meshes and save each one\n",
        "'''for i, mesh in enumerate(mesh_gen):\n",
        "    # Ensure the mesh has only one element\n",
        "    #mesh = mesh.extend(1)  # Create a single-element Meshes object\n",
        "\n",
        "    # Define the output path\n",
        "\n",
        "\n",
        "    # Save the mesh with textures included\n",
        "    save_mesh(mesh, mesh_path, binary=True, include_textures=True)\n",
        "    print(f\"Saved mesh to {mesh_path}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LelV0_kc6dvB",
        "outputId": "98942b3d-119d-4a88-d9c5-a80f8de6e2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i, mesh in enumerate(mesh_gen):\\n    # Ensure the mesh has only one element\\n    #mesh = mesh.extend(1)  # Create a single-element Meshes object\\n\\n    # Define the output path\\n\\n\\n    # Save the mesh with textures included\\n    save_mesh(mesh, mesh_path, binary=True, include_textures=True)\\n    print(f\"Saved mesh to {mesh_path}\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "# Util function for loading meshes\n",
        "from pytorch3d.io import load_objs_as_meshes, load_obj\n",
        "\n",
        "# Data structures and functions for rendering\n",
        "from pytorch3d.structures import Meshes\n",
        "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
        "from pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVPerspectiveCameras,\n",
        "    PointLights,\n",
        "    DirectionalLights,\n",
        "    Materials,\n",
        "    RasterizationSettings,\n",
        "    MeshRenderer,\n",
        "    MeshRasterizer,\n",
        "    SoftPhongShader,\n",
        "    TexturesUV,\n",
        "    TexturesVertex\n",
        ")\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "463EMJah__kC",
        "outputId": "3ef0216a-2bea-498b-bae4-8e974af1a664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Util function for loading meshes\\nfrom pytorch3d.io import load_objs_as_meshes, load_obj\\n\\n# Data structures and functions for rendering\\nfrom pytorch3d.structures import Meshes\\nfrom pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\\nfrom pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\\nfrom pytorch3d.renderer import (\\n    look_at_view_transform,\\n    FoVPerspectiveCameras, \\n    PointLights, \\n    DirectionalLights, \\n    Materials, \\n    RasterizationSettings, \\n    MeshRenderer, \\n    MeshRasterizer,  \\n    SoftPhongShader,\\n    TexturesUV,\\n    TexturesVertex\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
        "from plot_image_grid import image_grid'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqvQf26v_1lF",
        "outputId": "657fa8ea-427b-4964-d76b-766b47d54876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-06 00:25:21--  https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘plot_image_grid.py’\n",
            "\n",
            "plot_image_grid.py  100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-06 00:25:21 (29.3 MB/s) - ‘plot_image_grid.py’ saved [1608/1608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from pytorch3d.io import save_ply\n",
        "\n",
        "verts = mesh_gen.verts_packed()\n",
        "faces = mesh_gen.faces_packed()\n",
        "verts_rgb = mesh_gen.textures.verts_features_packed()\n",
        "\n",
        "# Save to PLY\n",
        "ply_path = Path(out_dir) / \"textured_mesh.ply\"\n",
        "save_ply(ply_path, verts, faces)\n",
        "print(f\"Saved PLY with vertex colors to {ply_path}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "avmsiubDCwi1",
        "outputId": "e2a95a6e-a3c0-4a76-85da-700060ec5063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b642a432e0e7>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save to PLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mply_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"textured_mesh.ply\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msave_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mply_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved PLY with vertex colors to {ply_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## display render"
      ],
      "metadata": {
        "id": "sy1HD1-5HZdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#images = SDFusion.renderer(mesh)\n",
        "#mesh.textures.faces_verts_textures_packed()\n",
        "from pytorch3d.renderer import PointLights\n",
        "\n",
        "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
        "lights.location = torch.tensor([0.2, 0.0, 0.0], device=device)[None]\n",
        "\n",
        "for i, mesh in enumerate(mesh_gen):\n",
        "    texture_image = mesh.textures.verts_features_padded().squeeze().cpu().numpy()\n",
        "    img_comb = SDFusion.renderer(mesh, lights=lights)\n",
        "    print(f\"TEXTURES ---- {mesh.textures}---\")\n",
        "    #img_comb = render_mesh(SDFusion.renderer, mesh, norm=False)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_comb[0, ..., :3].cpu().numpy())\n",
        "   # plt.imshow(img_comb.cpu().numpy())\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "MsWhUHpQ_sVd",
        "outputId": "8b357055-f20b-4254-8436-a5d449ac80a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTURES ---- <pytorch3d.renderer.mesh.textures.TexturesVertex object at 0x7a033c7674f0>---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for i, mesh in enumerate(mesh_gen):\n",
        "  plt.figure(figsize=(7,7))\n",
        "  texture_image=mesh.textures.verts_features_padded()\n",
        "  plt.imshow(texture_image.squeeze().cpu().numpy())\n",
        "  plt.axis(\"off\");'''\n",
        "for i, mesh in enumerate(mesh_gen):\n",
        "    plt.figure(figsize=(7, 7))\n",
        "\n",
        "    # Get vertex features (e.g., RGB values)\n",
        "    texture_image = mesh.textures.verts_features_padded()  # Shape: (1, N, 3)\n",
        "\n",
        "    # Check the shape of the texture\n",
        "    print(f\"Texture shape: {texture_image.shape}\")\n",
        "\n",
        "    # Visualize the texture as an array (flattening may be needed)\n",
        "    texture_image_np = texture_image.squeeze().cpu().numpy()  # Shape: (N, 3)\n",
        "    plt.imshow(texture_image_np, aspect='auto')  # Display as a continuous line\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Yqh-o5PDX-uS",
        "outputId": "938d414c-6dcf-4de6-b4f9-51632f54f0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texture shape: torch.Size([1, 8086, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import numpy as np\n",
        "\n",
        "# Extract vertex positions, faces, and vertex colors\n",
        "verts = mesh.verts_packed().cpu().numpy()  # (N, 3)\n",
        "faces = mesh.faces_packed().cpu().numpy()  # (F, 3)\n",
        "verts_rgb = mesh.textures.verts_features_packed().cpu().numpy()  # (N, 3)\n",
        "\n",
        "# Create a Trimesh object with vertex colors\n",
        "trimesh_mesh = trimesh.Trimesh(vertices=verts, faces=faces, vertex_colors=verts_rgb)#vertex_colors=(verts_rgb * 255).astype(np.uint8)\n",
        "\n",
        "# Save to .ply\n",
        "ply_path = Path(out_dir) / f\"newshape_{i}_{input_txt.replace(' ', '_')}.ply\"\n",
        "trimesh_mesh.export(ply_path)\n",
        "print(f\"Saved mesh with vertex colors to {ply_path}\")\n"
      ],
      "metadata": {
        "id": "H47SNXyvaArx",
        "outputId": "b79351be-c1a7-4ba9-be06-a4a8cf6f6459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved mesh with vertex colors to demo_results/newshape_0_A_round_red_color_chair_with_four_legs_0.5_meters_in_length_each.ply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.io import save_obj, save_ply\n",
        "\n",
        " # Assuming each mesh has a `textures` attribute with a Textures object\n",
        "for i, mesh in enumerate(mesh_gen):\n",
        "    verts, faces = mesh.verts_packed(), mesh.faces_packed()\n",
        "\n",
        "    # Save geometry and textures to .obj format\n",
        "    if hasattr(mesh, 'textures') and mesh.textures is not None:\n",
        "        vertex_colors = mesh.textures.verts_features_packed()  # Extract vertex colors\n",
        "\n",
        "        # Save to .obj without UVs but with vertex colors\n",
        "        obj_path = f\"{out_dir}/shape_{i}_{input_txt.replace(' ', '_')}_textured.obj\"\n",
        "        save_obj(obj_path, verts, faces)  # OBJ doesn't natively support vertex colors\n",
        "        print(f\"Saved OBJ to {obj_path} (vertex colors not directly supported in OBJ)\")\n",
        "\n",
        "        # Save to .ply with vertex colors\n",
        "        ply_path = f\"{out_dir}/shape_{i}_{input_txt.replace(' ', '_')}_textured.ply\"\n",
        "        save_ply(ply_path, verts, faces, verts_rgb=vertex_colors)\n",
        "        print(f\"Saved PLY to {ply_path} (with vertex colors)\")\n",
        "\n",
        "    else:\n",
        "        # Save without textures\n",
        "        obj_path = f\"{out_dir}/shape_{i}_{input_txt.replace(' ', '_')}.obj\"\n",
        "        save_obj(obj_path, verts, faces)\n",
        "        print(f\"Saved OBJ (no textures) to {obj_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "hrStyMmu3zUU",
        "outputId": "63f33869-29b8-49bb-dfeb-fcc3db5b8a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved OBJ to demo_results/shape_0_A_round_red_color_chair_with_four_legs_0.5_meters_in_length_each_textured.obj (vertex colors not directly supported in OBJ)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "save_ply() got an unexpected keyword argument 'verts_rgb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8adbce2a43ba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Save to .ply with vertex colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mply_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{out_dir}/shape_{i}_{input_txt.replace(' ', '_')}_textured.ply\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msave_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mply_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts_rgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertex_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved PLY to {ply_path} (with vertex colors)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: save_ply() got an unexpected keyword argument 'verts_rgb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1ZQCHmXovoo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "dzJRDnYIfERJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrvT6qzSziwP",
        "outputId": "4c07134d-682c-4ed0-8c96-e52e9ec98162"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test\n",
        "\n",
        "import gdown\n",
        "\n",
        "dataset_url = \"https://drive.google.com/drive/folders/1xtraL2jb9t3dQCbsJ91exnEJJohGQPIX\"\n",
        "id=\"1xtraL2jb9t3dQCbsJ91exnEJJohGQPIX\"\n",
        "output = \"data\"\n",
        "gdown.download_folder(id=id,output=output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "gSX_D9S93ed2",
        "outputId": "5f4bc318-0400-45c4-e31e-d3569d5b53ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1IsFlpu0HXJHe7yHwGprLwSkx8gy1qYHl bird.jpg\n",
            "Processing file 1BPvngBphD8X4_5a4ixGK53Z0YKkCNBZL catstatue.jpg\n",
            "Processing file 1AAk9Axdfu81qeqGwQU0lv_Wu6-mYnBRr frog_sweater.jpg\n",
            "Processing file 1ZAcpTT_JlPP4GutcGUDSmQrNI23ybwbO gsorabbit.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IsFlpu0HXJHe7yHwGprLwSkx8gy1qYHl\n",
            "To: /content/data/bird.jpg\n",
            "100%|██████████| 29.2k/29.2k [00:00<00:00, 45.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BPvngBphD8X4_5a4ixGK53Z0YKkCNBZL\n",
            "To: /content/data/catstatue.jpg\n",
            "100%|██████████| 10.8k/10.8k [00:00<00:00, 23.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AAk9Axdfu81qeqGwQU0lv_Wu6-mYnBRr\n",
            "To: /content/data/frog_sweater.jpg\n",
            "100%|██████████| 36.3k/36.3k [00:00<00:00, 15.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZAcpTT_JlPP4GutcGUDSmQrNI23ybwbO\n",
            "To: /content/data/gsorabbit.jpg\n",
            "100%|██████████| 15.9k/15.9k [00:00<00:00, 31.1MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/bird.jpg',\n",
              " 'data/catstatue.jpg',\n",
              " 'data/frog_sweater.jpg',\n",
              " 'data/gsorabbit.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data\n",
        "!ls\n",
        "import os\n",
        "\n",
        "os.mkdirs(\"BuildingNet_dataset_v0_1\",exist_ok=True)"
      ],
      "metadata": {
        "id": "EI6uBL2o5pMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "dataset_url = \"https://drive.google.com/drive/folders/169v-PBSDj-DIFiWI7HTUAQbna5atUgFW\"\n",
        "id=\"169v-PBSDj-DIFiWI7HTUAQbna5atUgFW\"\n",
        "\n",
        "output = \"BuildingNet_dataset_v0_1\"\n",
        "\n",
        "gdown.download_folder(id=id,output=output)"
      ],
      "metadata": {
        "id": "FENS6kq7zol6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd ..\n",
        "!ls"
      ],
      "metadata": {
        "id": "x2Gkn_gD54Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download the dataset\n",
        "# Replace this with the actual URL you get after filling the form\n",
        "\n",
        "dataset_filename = \"BuildingNet_dataset_v0_1.zip\"\n",
        "\n",
        "# Unzip to ./data/\n",
        "!unzip -q {dataset_filename} -d data\n"
      ],
      "metadata": {
        "id": "dbPQOsGyfHF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd preprocess\n",
        "!./launchers/launch_create_sdf_building.sh\n",
        "%cd ../"
      ],
      "metadata": {
        "id": "rLSYuaBc9y2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BuildingNet\n",
        "./launchers/train_vqvae-bnet.sh"
      ],
      "metadata": {
        "id": "cMQ4dxJw-cdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train VQVAE\n",
        "# ShapeNet\n",
        "#./launchers/train_vqvae_snet.sh\n",
        "\n",
        "# BuildingNet\n",
        "!./launchers/train_vqvae-bnet.sh\n",
        "\n",
        "#After training, copy the trained VQVAE checkpoint to the ./saved_ckpt folder.\n",
        "#Let's say the name of the checkpoints are\n",
        "#vqvae-snet-all.ckpt or\n",
        "#vqvae-bnet-all.ckpt.\n",
        "#This is necessary for training the Diffusion model. For SDFusion on various tasks, please see 2.~5. below.\n"
      ],
      "metadata": {
        "id": "pc8K4Up-AhlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Train SDFusion on ShapeNet and BuildingNet\n",
        "# ShapeNet\n",
        "#./launchers/train_sdfusion_snet.sh\n",
        "\n",
        "# BuildingNet\n",
        "!./launchers/train_sdfusion_bnet.sh\n"
      ],
      "metadata": {
        "id": "iWYQp2G8BLmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title text2shape\n",
        "#./launchers/train_sdfusion_img2shape.sh\n",
        "#Train SDFusion for text-guided shape generation\n",
        "\n",
        "# text2shape\n",
        "./launchers/train_sdfusion_txt2shape.sh\n"
      ],
      "metadata": {
        "id": "S-EJ9GX8BPRT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "c9bb85e944c303a90ba1b7f3901817f7bc3ecb5f736863b2299a6fa67a7b3c89"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}